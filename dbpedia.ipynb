{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88adcc1-06f2-4b72-af89-b16b154c6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 15:28:21.909609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-30 15:28:21.909702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c80fd6-fded-4ac3-983c-262dd7586964",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/dbpedia_csv/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d76b2be-b02a-41ef-92ea-bb6538c2ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/dbpedia_csv/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bff7453-dcba-4550-80b2-0af7abe1f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Class', 'Title', 'Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7b3858-0a1d-4b38-b3dd-f6c1d5b6f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8912028d-73d5-46e4-8236-a578a7a946d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adfaed8-52b6-4342-b200-ab80c46fca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E. D. Abbott Ltd</td>\n",
       "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Schwan-Stabilo</td>\n",
       "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Q-workshop</td>\n",
       "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Marvell Software Solutions Israel</td>\n",
       "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Bergan Mercy Medical Center</td>\n",
       "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                              Title  \\\n",
       "0      1                   E. D. Abbott Ltd   \n",
       "1      1                     Schwan-Stabilo   \n",
       "2      1                         Q-workshop   \n",
       "3      1  Marvell Software Solutions Israel   \n",
       "4      1        Bergan Mercy Medical Center   \n",
       "\n",
       "                                             Content  \n",
       "0   Abbott of Farnham E D Abbott Limited was a Br...  \n",
       "1   Schwan-STABILO is a German maker of pens for ...  \n",
       "2   Q-workshop is a Polish company located in Poz...  \n",
       "3   Marvell Software Solutions Israel known as RA...  \n",
       "4   Bergan Mercy Medical Center is a hospital loc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee6749a-db0e-4554-9bd1-55e9fe3a5022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TY KU</td>\n",
       "      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Odd Lot Entertainment</td>\n",
       "      <td>OddLot Entertainment founded in 2001 by longt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Henkel</td>\n",
       "      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GOAT Store</td>\n",
       "      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RagWing Aircraft Designs</td>\n",
       "      <td>RagWing Aircraft Designs (also called the Rag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                     Title  \\\n",
       "0      1                     TY KU   \n",
       "1      1     Odd Lot Entertainment   \n",
       "2      1                    Henkel   \n",
       "3      1                GOAT Store   \n",
       "4      1  RagWing Aircraft Designs   \n",
       "\n",
       "                                             Content  \n",
       "0   TY KU /taɪkuː/ is an American alcoholic bever...  \n",
       "1   OddLot Entertainment founded in 2001 by longt...  \n",
       "2   Henkel AG & Company KGaA operates worldwide w...  \n",
       "3   The GOAT Store (Games Of All Type Store) LLC ...  \n",
       "4   RagWing Aircraft Designs (also called the Rag...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d19abe-e9f7-4bc9-be25-28e17e35cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     40000\n",
       "2     40000\n",
       "3     40000\n",
       "4     40000\n",
       "5     40000\n",
       "6     40000\n",
       "7     40000\n",
       "8     40000\n",
       "9     40000\n",
       "10    40000\n",
       "11    40000\n",
       "12    40000\n",
       "13    40000\n",
       "14    40000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9486edaa-a744-47b9-ab0a-3dd7997525c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5000\n",
       "2     5000\n",
       "3     5000\n",
       "4     5000\n",
       "5     5000\n",
       "6     5000\n",
       "7     5000\n",
       "8     5000\n",
       "9     5000\n",
       "10    5000\n",
       "11    5000\n",
       "12    5000\n",
       "13    5000\n",
       "14    5000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d08729-11ec-4b05-9107-ed2e3c131db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e671ce-d78f-438e-8507-1d66e88642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the identifier of the model. The library need this ID to download the weights and initialize the architecture\n",
    "# here is all the supported ones:\n",
    "# https://huggingface.co/transformers/pretrained_models.html\n",
    "xlnet_model = 'xlnet-base-cased'\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092cd9f9-322a-4136-b3df-6c497d2d2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = train['Content']\n",
    "labels = train['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(content, labels, train_size=7000, test_size=0.15, random_state=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5183856e-ba79-47f6-ad3e-5c03ddd87ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({13: 536, 14: 534, 12: 527, 11: 515, 9: 514, 10: 511, 8: 502, 4: 500, 2: 495, 7: 493, 6: 477, 5: 472, 3: 467, 1: 457})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3524207-3403-4566-89b5-7ca7e0c5539f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d88601b-525a-4192-9fc6-2c842c1845c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dbfd899-0600-4e44-9bbb-4c2b556cccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xlnet(mname):\n",
    "    \"\"\" Creates the model. It is composed of the XLNet main block and then\n",
    "    a classification head its added\n",
    "    \"\"\"\n",
    "    # Define token ids as inputs\n",
    "    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n",
    "\n",
    "    # Call XLNet model\n",
    "    xlnet = TFXLNetModel.from_pretrained(mname)\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "\n",
    "    # CLASSIFICATION HEAD \n",
    "    # Collect last step from last hidden state (CLS)\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    # Apply dropout for regularization\n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "    # Final output \n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "\n",
    "    # Compile model\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e7f577-4ee1-4dfb-baa0-4c054c82bd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 15:30:34.251320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-30 15:30:34.251411: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-30 15:30:34.251489: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pri): /proc/driver/nvidia/version does not exist\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n",
      "/home/pri/.local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "xlnet = create_xlnet(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07342c62-a58d-4fe2-8041-e361be8b7bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " word_inputs (InputLayer)    [(None, 120)]             0         \n",
      "                                                                 \n",
      " tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n",
      " l)                          hidden_state=(None, 120,            \n",
      "                              768),                              \n",
      "                              mems=((120, None, 768),            \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768),                  \n",
      "                              (120, None, 768)),                 \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 1, 768)           0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (None, 768)              0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 768)               0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,719,105\n",
      "Trainable params: 116,719,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xlnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f60455-d94b-4f59-9a71-142026f7539c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1b108-24b1-4c93-8a8c-186d0f86da75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "542295bb-8cb5-4235-a4c4-d9b0aead2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(content, tokenizer, max_len=120):\n",
    "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
    "    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in content]\n",
    "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
    "    ids = np.array([a['attention_mask'] for a in inps])\n",
    "    segments = np.array([a['token_type_ids'] for a in inps])\n",
    "    return inps, inp_tok, ids, segments\n",
    "\n",
    "def warmup(epoch, lr):\n",
    "    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n",
    "    However, as we are finetuning for few epoch it's not crucial.\n",
    "    \"\"\"\n",
    "    return max(lr +1e-6, 2e-5)\n",
    "\n",
    "def plot_metrics(pred, true_labels):\n",
    "    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n",
    "    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
    "    auc = roc_auc_score(true_labels, pred)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='red')\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b75b714-b57f-4c23-9824-189528b985f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/pri/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inps, inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b14fdeeb-5917-41ae-be16-6b0ae4d8a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a4ad7e-a488-41f1-902b-8df2cd668797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    }
   ],
   "source": [
    "hist = xlnet.fit(x=inp_tok, y=y_train, epochs=15, batch_size=16, validation_split=.15, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdee6f-ec95-4157-a357-e829a39b37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tok, ids, segments = get_inputs(X_test, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5229fd-bb34-4c01-8c4c-57b455adfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xlnet.predict(inp_tok, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1af605-0f9e-406c-9860-94cb2f116479",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(preds, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b949f-ce8a-4d14-beb2-b066ab559e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9c0a99-e355-4836-bc88-d56493ba9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b5e8e-a4f2-4a7b-a531-c9dd6fef8ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
